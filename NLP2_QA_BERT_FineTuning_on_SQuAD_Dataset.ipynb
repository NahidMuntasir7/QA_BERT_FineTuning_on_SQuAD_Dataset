{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "Classification and Question Answering (QA) are two key tasks in Natural Language Processing (NLP). In classification, a model assigns predefined labels to input text (e.g., identifying a sentence as positive or negative, or categorizing it as assertive, interrogative, etc.).\n",
        "\n",
        "In contrast, QA involves finding or generating an answer to a given question based on a context passage. While classification focuses on categorizing text, QA focuses on understanding and extracting specific information from text.\n",
        "\n",
        "QA Example:\n",
        "\n",
        "Context: \"Albert Einstein developed the theory of relativity in the early 20th century.\"\n",
        "\n",
        "Question: \"Who developed the theory of relativity?\"\n",
        "\n",
        "Answer: \"Albert Einstein\"\n"
      ],
      "metadata": {
        "id": "z2yjCSj5RGWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "OZ8TVMUd8k54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBBdPCd2RZZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfd89b2-37b9-47f5-ffb9-9f38dcfdc47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "import torch\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "TkgSbUwP7dKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load and Explore Dataset"
      ],
      "metadata": {
        "id": "Io_JQYLR8pQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load SQuAD v1.1\n",
        "dataset = load_dataset(\"squad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "d6d7fa8e16da4e0bb3b4d72c240d729b",
            "3e47462e268a4abeab256a1f1bd17e1f",
            "8aef88ecb8d84768add14d26854cca00",
            "9edb6f57812e41baad87c5c356faf273",
            "c372a088a54542f5928f5d32877df490",
            "b6134e1e9cdd48f1a2868382d526e1eb",
            "21564bd3062f49e58d9f7f5d9096138c",
            "28b755265b4640dfaa04e3a003cc57e9",
            "82448a738989475383302bda0d7f2d05",
            "14a3d554348746c29629f254c020b36a",
            "6bff6697f8454c4ba9cc866ca29462b6",
            "b5792b530e6b4f40a9103ddd31287790",
            "b9407d12fb0b4818a2ff6ab584e96bff",
            "42227f3c76e74afd8dcb6d71ae9a7c07",
            "fe54f5a4b37640b0bbda096dde394eb2",
            "2242a66b1d0f4ffcb056cd2d664988fe",
            "edb909ba1b734639bd380a03cde9247d",
            "48657ba7187a48d1a302e5b3f12e6184",
            "0f2e6d136d9746b3b403a52378ca600c",
            "61cd84da05c04387a0974cdb13a78b29",
            "3c1ee85effd54ad7adc15c68c17eb96d",
            "88bc85a1ba8941db8eee0cefe7ffeb73",
            "ec682bb29b43446aa5aa7c0de32dd106",
            "f9ec20460fc943f48ef9130beb11a425",
            "de02e5e6657e40dc9803caf12c2e3cd6",
            "4d040abb5bb8483c836e55e21fb7d650",
            "4f95d5e6d236430b9e539dd78ab2c722",
            "c4f7f54cc7a34fc58a082cfc91aa48bf",
            "257985ded431419da478cab967557fbc",
            "c992f0c4f4914673a8924f3714ed3a28",
            "80110512819d487195865ddd80307721",
            "5b6a859cb4f24575a491f040d910e777",
            "fffd72862cde48b88f7642cf44ff081c",
            "870c53f0fb584e5ea16419f86928003a",
            "4415c0be4d59499db35825b35bd3bf9b",
            "d3d71530e8bb4da596637cfc44908330",
            "8f6b7456105b4d55976bdd2edb97535d",
            "98cab778ca374e4c911eb391d0490a0d",
            "91c0ea1503f645398ec14f41a0cca322",
            "4d2fd3c133f84e4a940a205f64179c84",
            "bf3e938da7af4fb99f5e94babd89137f",
            "ed70d0b6336544d38e95db2e2fb2de5b",
            "254d73773eee432fa1f203af788b73d0",
            "7b8a8b69a7b9472eb6fad0b4646ab2dd",
            "2b245c10c2db40cfb3127edb6f872947",
            "62c505c13004481b95c1b5c6b4ec75c1",
            "1e591238eb2047f3a99b84bc21c86944",
            "28d6c90bbc1b4012ab75abcb92721b5b",
            "94ff25481c8b4b88a8f7540687769e88",
            "9a2a3d26ef974bceb77b1905e3524a79",
            "cdfe9e26c47141d6a69834ee5d98b241",
            "3657fc3a50424cf488a600c6c0e93f1b",
            "02f700df8bb04462a6428205f89c7c4c",
            "1f443873b1614b13837797a998dc1e1c",
            "d71aee9bad684689a3eaa130fe84dfd5"
          ]
        },
        "id": "IFZuI3NHTEfJ",
        "outputId": "34eeaff9-5a88-4e99-a979-f62177932d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6d7fa8e16da4e0bb3b4d72c240d729b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5792b530e6b4f40a9103ddd31287790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/validation-00000-of-00001.par(…):   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec682bb29b43446aa5aa7c0de32dd106"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "870c53f0fb584e5ea16419f86928003a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b245c10c2db40cfb3127edb6f872947"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8FJEocR9NAu",
        "outputId": "acd5f6ed-9597-4761-cc38-1b3647287bbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 87599\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 10570\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore a sample\n",
        "print(dataset['train'][0])\n",
        "\n",
        "import pprint\n",
        "pprint.pprint(dataset[\"train\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhG29WTb7iJ4",
        "outputId": "22836282-d663-4c4c-9a27-3128ebb55a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n",
            "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
            " 'context': 'Architecturally, the school has a Catholic character. Atop the '\n",
            "            \"Main Building's gold dome is a golden statue of the Virgin Mary. \"\n",
            "            'Immediately in front of the Main Building and facing it, is a '\n",
            "            'copper statue of Christ with arms upraised with the legend '\n",
            "            '\"Venite Ad Me Omnes\". Next to the Main Building is the Basilica '\n",
            "            'of the Sacred Heart. Immediately behind the basilica is the '\n",
            "            'Grotto, a Marian place of prayer and reflection. It is a replica '\n",
            "            'of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
            "            'appeared to Saint Bernadette Soubirous in 1858. At the end of the '\n",
            "            'main drive (and in a direct line that connects through 3 statues '\n",
            "            'and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
            " 'id': '5733be284776f41900661182',\n",
            " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes '\n",
            "             'France?',\n",
            " 'title': 'University_of_Notre_Dame'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0]['context']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yD2chsBl7n3s",
        "outputId": "eb124f85-1394-40a2-8303-42ec1b4dcf29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization"
      ],
      "metadata": {
        "id": "J6BJN-Mq8H40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=384,\n",
        "        truncation=\"only_second\",\n",
        "        stride=128,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    # Map each span back to the original example\n",
        "    for i, offsets in enumerate(inputs[\"offset_mapping\"]):\n",
        "        input_ids = inputs[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        sample_index = inputs[\"overflow_to_sample_mapping\"][i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            start_positions.append(cls_index)\n",
        "            end_positions.append(cls_index)\n",
        "        else:\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Find token indices\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # If answer out of span\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                start_positions.append(cls_index)\n",
        "                end_positions.append(cls_index)\n",
        "            else:\n",
        "                # Start token\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                start_positions.append(token_start_index - 1)\n",
        "                # End token\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                end_positions.append(token_end_index + 1)\n",
        "\n",
        "    inputs[\"start_positions\"] = start_positions\n",
        "    inputs[\"end_positions\"] = end_positions\n",
        "    return inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "48042dc1947e4fbfa92a2602b65be621",
            "03ceb4c7daaa46f5bd082587dac06acb",
            "809047fc2478454f8f2d0fe451a2598b",
            "31aae074082d4a5f8f17809a1e06e057",
            "e610100626694f4aa1f87331964dce22",
            "476072b58c3f4cb8b1decf343a0216be",
            "983ff32ce36a4f679bd46f655931028c",
            "f3e34ebb89264cb1ae687f248b4aa5ac",
            "443d9c584948460ea537fceb2dd08b07",
            "0ae18cdfa48d46e4bcb378c185f8871e",
            "179ce10864e54119b5aefbda5ccffedb",
            "bab0f1fb425841a1b9e40cf88fd3a956",
            "ef70a75ab070495abd125e7a7f6d297f",
            "f506b2a0b61441ecbd29967f6d8a8242",
            "b7a59d2a49744aa7a9cf152625b0f332",
            "201c025b1f424e198426faec2d81e35c",
            "fd54f7608746434b8503db5db41b5e1d",
            "fa7e5e043d204747b354a5cdb6748dd6",
            "808ae10aad304afd935f02e0cd006774",
            "71bbef5447d345498e1d7bfe775d2356",
            "201294df54904347a218c6eb07e58c51",
            "43ebdf7d39544738b2b26cdb0deede5e",
            "3991274a938d4d3fa3b55ffcf3b072ff",
            "5f34629d7920486f88bd8306c6860dd0",
            "1c56b871228d4e9d8c9036fdfacc1835",
            "6ccaca0cdc6b43f387dcb96663bb1541",
            "43f96a9cc1e748399fe382199eec0bad",
            "3a623e5caab3483e85bb1503312ec9d9",
            "3ca0407bd1ff4c81a0f713aa23986f95",
            "71110b9e3c9e4da3a7e095036954d308",
            "0b58ffec5bcc48c6bd729bac8db67a81",
            "9e30b2f90aac4db1a32370e2fea300fd",
            "c5fe7fc01a4f4f0d8b787f12150c9be5",
            "4a8f3b9ca2684dc5a054678a290a5431",
            "c298c22addd44489a78a879ae019fdb6",
            "8493a9aa6a58416c948858e18a886aa8",
            "d1962fbf7c68402dbe41923c3528c0f2",
            "fe57e4babc0d4f08bc7d0d211cac9d79",
            "f2b4dcc9ae3f4374b6b6717e21e31fc7",
            "0b8827b86ed6471a8d73eaecbbfd9b39",
            "5169c1f49dc049c5961d4388c32c309f",
            "11803c21cf4b49c2a4b8d892387f5111",
            "ce80e69b9ab74ebbbbecfbd236b96020",
            "e44f9d1fad4e4dd6847dc8c85475fde9",
            "d620a4d7ec1e479ba02ed69e66f3cc11",
            "f151a3af5ac94a339558baea4c41b085",
            "d00e1b97e5824c308d24af96a4447dd7",
            "5831590a3e914417a91aae2a3ccb3aa5",
            "7b2f8dcadbc74db1a09c897c4781a7db",
            "ec02587652cf4d139246d5e5e98b2270",
            "1abdfc955aee42be8552b05e5a1d9ab3",
            "82a29df4d7ee4289b830d2dc4330ab44",
            "7f89eac047604aa7a2a32c29bd9ee50d",
            "8c443c659c4d431abb1d23e62943002b",
            "97402ab10c11461cab69c447cb5fe65d",
            "e108548fef5b41fba9393c927666ecdf",
            "3fddfe806b2c4e7aa7cd825a42203c96",
            "266df9b625f8448dbd8ef6878bf837b9",
            "f62dbdf0be454069a275349e6ebb7579",
            "29bc844fa1be4e0193f97c7d910bc0b8",
            "4af764e423ad456b901bb63eb4987508",
            "07c2acf52bd64bf5bf3049365e6adcce",
            "74880f6b8d174f87977a1ebb46014955",
            "61206b5b82e4429598d0fbc2f4c6efaf",
            "bbc20e3a363c4cbe8e23df04cc8b461c",
            "142fba17beae46c7b60b85c3c07176ab"
          ]
        },
        "id": "nx-DY_v68KN9",
        "outputId": "0177579e-6685-4744-e521-ba8ab5317981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48042dc1947e4fbfa92a2602b65be621"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bab0f1fb425841a1b9e40cf88fd3a956"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3991274a938d4d3fa3b55ffcf3b072ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a8f3b9ca2684dc5a054678a290a5431"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d620a4d7ec1e479ba02ed69e66f3cc11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e108548fef5b41fba9393c927666ecdf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Setup"
      ],
      "metadata": {
        "id": "N8RcOu7B8whn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "83334d0d715d4630847c9c9eee796910",
            "8dce9b1e6bdc47cfb8f8e03ce07565d2",
            "d8187e09cce141ccba0de745a59de8b3",
            "5a3952df6b764997b7e61a444c4d5948",
            "2b05a117bba1417aa3efa49095dd8099",
            "740730cf64294ceb8312f1be82c53ed9",
            "a884c6624b614617996037957471de59",
            "b9ab672281e24f7cbaf252fd8a977034",
            "0dece9758b8446cfaf223bb17930efa0",
            "edd5296e5d6b4373a679cb0054c72950",
            "f1f56f1842ad42a793d313e65a66980c"
          ]
        },
        "id": "ds9Zn4a78zSx",
        "outputId": "f1103167-8af5-41fb-dac4-290e3e88e539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83334d0d715d4630847c9c9eee796910"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tuning"
      ],
      "metadata": {
        "id": "b8TAxqUd84rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load metric\n",
        "metric = evaluate.load(\"squad\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    start_logits, end_logits = eval_pred.predictions\n",
        "    start_labels, end_labels = eval_pred.label_ids\n",
        "\n",
        "    start_preds = np.argmax(start_logits, axis=1)\n",
        "    end_preds = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    # Loop over each example\n",
        "    for i in range(len(start_preds)):\n",
        "        input_ids = tokenized_datasets[\"validation\"][i][\"input_ids\"]\n",
        "        # Decode predicted answer\n",
        "        pred_text = tokenizer.decode(input_ids[start_preds[i]:end_preds[i]+1])\n",
        "        # Decode true answer\n",
        "        true_text = tokenizer.decode(input_ids[start_labels[i]:end_labels[i]+1])\n",
        "\n",
        "        predictions.append({\"id\": str(i), \"prediction_text\": pred_text})\n",
        "        references.append({\"id\": str(i), \"answers\": {\"text\": [true_text], \"answer_start\": [0]}})\n",
        "\n",
        "    results = metric.compute(predictions=predictions, references=references)\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.1,\n",
        "    report_to=\"none\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"].select(range(10000)),\n",
        "    eval_dataset=tokenized_datasets[\"validation\"].select(range(2000)),\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "d05fa1d7e81b45218a443ca0065485c5",
            "68cc838aadf3442ab034fae50df3a0df",
            "14112d346b454669a2a89cca1e4c3396",
            "f95b1d3a184a493fb132a98829d207f8",
            "c3d3b404d2444fc99894cf2eb255e6fa",
            "a10408b498394d7abfea0304e3caf45c",
            "b99bf5faab404284803e525d745e263f",
            "2e014afdf6b3469fa26390dcbd9512ab",
            "79cddc10e1924e619952826acd105214",
            "ce59f22dda434b929b760bdeaee20e48",
            "ffbcde49cc6f486db9e1dc418145b530",
            "8b67aeb3697f44d6a655f71412d5acf1",
            "0a3336ea3dda41fc9274cacdd4e47c7d",
            "73940e930f1340dc9c559106c74799d7",
            "37bb4b45ac074f5a987e03b1fcc57bbf",
            "605287389458459e870550184206ba83",
            "c40629dd69994313a2f68d00e7c5376d",
            "8004820dbe3e487781fc3e6b1b42e1e1",
            "adbe4f95feb741a0b2ef6da26d9c35bf",
            "1ecedec2fa8940959cd0d368142cab6d",
            "4d4d0a299dbd4fc48d644984c3bec37f",
            "b6c37fe460f14c9d8c059c7c62b8f1a7"
          ]
        },
        "id": "9v4eIyjc86i0",
        "outputId": "7460e7de-1442-4bf6-8451-28b35689bb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d05fa1d7e81b45218a443ca0065485c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b67aeb3697f44d6a655f71412d5acf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 25:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.502800</td>\n",
              "      <td>1.496712</td>\n",
              "      <td>52.800000</td>\n",
              "      <td>64.389361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.118900</td>\n",
              "      <td>1.442450</td>\n",
              "      <td>55.800000</td>\n",
              "      <td>67.272621</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=1.6723446014404297, metrics={'train_runtime': 1530.8809, 'train_samples_per_second': 13.064, 'train_steps_per_second': 0.817, 'total_flos': 3919451351040000.0, 'train_loss': 1.6723446014404297, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluation & Custom Testing"
      ],
      "metadata": {
        "id": "a7EoRNfW8_6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Validation\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Dlc2yX_Q-Xp9",
        "outputId": "64c0e754-9557-4bdd-9751-eec1d1b93f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:44]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.4424500465393066,\n",
              " 'eval_exact_match': 55.8,\n",
              " 'eval_f1': 67.27262066158745,\n",
              " 'eval_runtime': 48.9564,\n",
              " 'eval_samples_per_second': 40.853,\n",
              " 'eval_steps_per_second': 2.553,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def answer_question(question, context):\n",
        "\n",
        "    inputs = tokenizer(question, context, return_tensors=\"pt\", truncation=True, max_length=384).to(device)\n",
        "\n",
        "    # Get model outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    start_idx = torch.argmax(outputs.start_logits)\n",
        "    end_idx = torch.argmax(outputs.end_logits)\n",
        "\n",
        "    # Decode the answer from the input_ids\n",
        "    answer = tokenizer.decode(inputs[\"input_ids\"][0][start_idx:end_idx+1])\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Custom Testing\n",
        "ques1 = \"Who developed the theory of relativity?\"\n",
        "context1 = \"Albert Einstein developed the theory of relativity in the early 20th century.\"\n",
        "\n",
        "ques2 = \"In which century did Einstein develop his theory?\"\n",
        "context2 = \"Albert Einstein developed the theory of relativity in the early 20th century.\"\n",
        "\n",
        "print(\"Question:\", ques1)\n",
        "print(\"Answer:\", answer_question(ques1, context1))\n",
        "print(\"Question:\", ques2)\n",
        "print(\"Answer:\", answer_question(ques2, context2))\n",
        "\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# More Testing\n",
        "\n",
        "# Context\n",
        "context = \"The Eiffel Tower, located in Paris, France, was completed in 1889 and is one of the most famous landmarks in the world.\"\n",
        "\n",
        "# Custom questions\n",
        "questions = [\n",
        "    \"Where is the Eiffel Tower located?\",\n",
        "    \"When was the Eiffel Tower completed?\",\n",
        "    \"What is the Eiffel Tower famous for?\",\n",
        "    \"Which city has the Eiffel Tower?\",\n",
        "]\n",
        "\n",
        "# Testing\n",
        "for q in questions:\n",
        "    print(\"Question:\", q)\n",
        "    print(\"Answer:\", answer_question(q, context))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_xikiGc9CVt",
        "outputId": "34fe29b3-daf8-41ac-9246-f79a14c92f1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Who developed the theory of relativity?\n",
            "Answer: albert einstein\n",
            "Question: In which century did Einstein develop his theory?\n",
            "Answer: 20th\n",
            "\n",
            "\n",
            "Question: Where is the Eiffel Tower located?\n",
            "Answer: paris, france\n",
            "\n",
            "Question: When was the Eiffel Tower completed?\n",
            "Answer: 1889\n",
            "\n",
            "Question: What is the Eiffel Tower famous for?\n",
            "Answer: one of the most famous landmarks in the world\n",
            "\n",
            "Question: Which city has the Eiffel Tower?\n",
            "Answer: paris, france\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project demonstrates the fine-tuning of a pre-trained BERT model for extractive Question Answering. By training on the SQuAD dataset, which contains questions, contexts, and answers, the model learns to identify the precise start and end tokens of answers within a passage. The input text is tokenized into a format suitable for BERT, and the model is trained to predict the token indices for the answer span. After two epochs of training, the model achieved an evaluation loss of 1.44, an Exact Match (EM) score of 55.8%, and an F1 score of 67.27%, showing its ability to extract answers with reasonable accuracy. I also observed the model’s efficiency, with evaluation running for about 49 seconds and processing roughly 41 samples per second. This project helped me understand the importance of task-specific fine-tuning, tokenization, and performance evaluation, giving me practical insights into building effective QA systems."
      ],
      "metadata": {
        "id": "pVW76cjfSoU2"
      }
    }
  ]
}
